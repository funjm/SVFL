{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "546a0720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed490935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "FC1_SIZE = 200\n",
    "FC2_SIZE = 100\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, classes, input_size):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.hidden1_output = None\n",
    "        self.hidden2_output = None\n",
    "\n",
    "        FC1_SIZE = 2*input_size\n",
    "        print(\"FC1_SIZE is :{}\\nFC2_SIZE is {}\".format(FC1_SIZE, FC2_SIZE))\n",
    "\n",
    "        # =======================无trick=======================\n",
    "        self.fc1 = nn.Linear(input_size, FC1_SIZE)\n",
    "        self.fc2 = nn.Linear(FC1_SIZE, FC2_SIZE)\n",
    "        self.fc3 = nn.Linear(FC2_SIZE, classes)\n",
    "\n",
    "        # # =======================tricks: dropout, BN=======================\n",
    "        # self.fc1 = nn.Linear(input_size, FC1_SIZE)\n",
    "        # self.bn1 = nn.BatchNorm1d(num_features=FC1_SIZE)\n",
    "        #\n",
    "        # self.dropout = nn.Dropout(p=0.3)\n",
    "        #\n",
    "        # self.fc2 = nn.Linear(FC1_SIZE, FC2_SIZE)\n",
    "        # self.bn2 = nn.BatchNorm1d(num_features=FC2_SIZE)\n",
    "        # self.fc3 = nn.Linear(FC2_SIZE, classes)\n",
    "\n",
    "\n",
    "\n",
    "        # self.layers = nn.Sequential(\n",
    "        #     nn.Linear(input_size, 200),\n",
    "        #     nn.BatchNorm1d(num_features=200),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(200, 100),\n",
    "        #     nn.BatchNorm1d(num_features=100),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(100, classes)\n",
    "        # )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Forward pass'''\n",
    "        # =======================无trick=======================\n",
    "        x = self.fc1(x)\n",
    "        self.hidden1_output = x\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        self.hidden2_output = x\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        # # =======================tricks: dropout, BN=======================\n",
    "        # x = self.fc1(x)\n",
    "        # # 记录hidden1的输出\n",
    "        # self.hidden1_output = x\n",
    "        # x = self.bn1(x)\n",
    "        # x = F.relu(x)\n",
    "        #\n",
    "        # x = self.fc2(x)\n",
    "        # # 记录hidden1的输出\n",
    "        # self.hidden2_output = x\n",
    "        # x = self.bn2(x)\n",
    "        # x = F.relu(x)\n",
    "        #\n",
    "        # x = self.dropout(x)\n",
    "        #\n",
    "        # x = self.fc3(x)\n",
    "\n",
    "        return x, self.hidden1_output, self.hidden2_output\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight.data, 0, 0.1)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec313a5",
   "metadata": {},
   "source": [
    "# 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1f811cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC1_SIZE is :152\n",
      "FC2_SIZE is 100\n"
     ]
    }
   ],
   "source": [
    "net_new = MLP(classes=10, input_size=76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "700cb9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_state_dict = \"../saved_model/mfeat-fou.pkl\"\n",
    "state_dict_load = torch.load(path_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31c1d2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载前:  tensor([-0.1069, -0.0318,  0.1046, -0.0002,  0.0290,  0.0969, -0.0630, -0.0435,\n",
      "         0.0404,  0.1044,  0.1145,  0.0877, -0.0581,  0.0917,  0.0379,  0.0802,\n",
      "         0.0784,  0.0308,  0.0006, -0.0526, -0.0963,  0.0969,  0.1028,  0.0729,\n",
      "        -0.1120, -0.0436,  0.0858,  0.0588,  0.0490, -0.0831, -0.1055,  0.0364,\n",
      "         0.0901, -0.0278,  0.0084, -0.0118,  0.0609,  0.0437, -0.0938,  0.0346,\n",
      "         0.0993, -0.0032,  0.0021,  0.0947,  0.0760,  0.1101, -0.0608, -0.0831,\n",
      "        -0.1041, -0.0659,  0.0309, -0.0973,  0.0328,  0.1081,  0.1102, -0.0674,\n",
      "         0.0190,  0.0308, -0.0223,  0.0507, -0.0846,  0.0884, -0.1124, -0.0528,\n",
      "         0.0376,  0.0668,  0.0209, -0.0639, -0.0837,  0.0069,  0.1054, -0.0990,\n",
      "         0.0433,  0.0845, -0.1128,  0.0860], grad_fn=<SelectBackward>)\n",
      "加载后:  tensor([ 0.1766,  0.1869,  0.0384, -0.0698, -0.1771,  0.1209, -0.0867,  0.1388,\n",
      "         0.0137,  0.0360, -0.0255, -0.0432,  0.0514, -0.0565, -0.1049, -0.1762,\n",
      "         0.0926,  0.1054,  0.0993, -0.1239,  0.0232,  0.0411, -0.0545,  0.1181,\n",
      "        -0.1075,  0.1310,  0.1688, -0.0031,  0.1419, -0.0905,  0.0811, -0.0861,\n",
      "         0.1768, -0.0319, -0.1411,  0.0402,  0.0159, -0.0238, -0.0191, -0.0171,\n",
      "        -0.1630,  0.0764, -0.0944,  0.1212, -0.1823,  0.0376, -0.0301, -0.1606,\n",
      "         0.1330,  0.0614,  0.0405,  0.2159,  0.0509, -0.0285,  0.0965,  0.0884,\n",
      "         0.1265, -0.0923,  0.0593, -0.0384, -0.0522, -0.0790,  0.1762, -0.0917,\n",
      "         0.0624,  0.0614, -0.0761, -0.0051, -0.0876,  0.1221, -0.1156, -0.0207,\n",
      "        -0.0894, -0.0218, -0.0139,  0.2351], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(\"加载前: \", net_new.fc1.weight[0, ...])\n",
    "net_new.load_state_dict(state_dict_load)\n",
    "print(\"加载后: \", net_new.fc1.weight[0, ...])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f199df95",
   "metadata": {},
   "source": [
    "# 批处理加载模型,dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9577a572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "DATASIZE = 2000\n",
    "# !!!如果改变此参数,split_datasets中的也需要改\n",
    "TRAIN_PRECENT = 0.8\n",
    "CLASS_NUM = 10\n",
    "\n",
    "\n",
    "class handWritten_Dataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, train=True):\n",
    "        \"\"\"\n",
    "        mfeat-fou的Dataset\n",
    "        :param data_path: str, 数据集所在路径\n",
    "        :param transform: torch.transform，数据预处理\n",
    "        \"\"\"\n",
    "\n",
    "        self.label_name = {\"0\": 0, \"1\": 1}\n",
    "        self.class_size = self.get_class_size(train)\n",
    "        self.data_info = self.get_img_info(data_path)\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data, label = self.data_info[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "\n",
    "    # @staticmethod\n",
    "    def get_class_size(self, train):\n",
    "        class_size = int(DATASIZE*TRAIN_PRECENT/CLASS_NUM)\n",
    "        if not train:\n",
    "            class_size = 200 - class_size\n",
    "        return class_size\n",
    "\n",
    "    # @staticmethod\n",
    "    def get_img_info(self, file_path):\n",
    "        data_info = list()\n",
    "        train_data = np.load(file_path)\n",
    "        for i, data in enumerate(train_data):\n",
    "            label = int(i / self.class_size)\n",
    "            data_info.append((data, label))\n",
    "\n",
    "        # print(data_info[0])\n",
    "        return data_info\n",
    "\n",
    "    def get_features_size(self):\n",
    "        return len(self.data_info[0][0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49f1d742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批处理\n",
    "featureSet_list = ['mfeat-fou', 'mfeat-fac', 'mfeat-kar', 'mfeat-pix', 'mfeat-zer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d3f32",
   "metadata": {},
   "source": [
    "## 加载到list中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6b8f6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC1_SIZE is :152\n",
      "FC2_SIZE is 100\n",
      "加载后:  tensor([ 0.1766,  0.1869,  0.0384, -0.0698, -0.1771,  0.1209, -0.0867,  0.1388,\n",
      "         0.0137,  0.0360, -0.0255, -0.0432,  0.0514, -0.0565, -0.1049, -0.1762,\n",
      "         0.0926,  0.1054,  0.0993, -0.1239,  0.0232,  0.0411, -0.0545,  0.1181,\n",
      "        -0.1075,  0.1310,  0.1688, -0.0031,  0.1419, -0.0905,  0.0811, -0.0861,\n",
      "         0.1768, -0.0319, -0.1411,  0.0402,  0.0159, -0.0238, -0.0191, -0.0171,\n",
      "        -0.1630,  0.0764, -0.0944,  0.1212, -0.1823,  0.0376, -0.0301, -0.1606,\n",
      "         0.1330,  0.0614,  0.0405,  0.2159,  0.0509, -0.0285,  0.0965,  0.0884,\n",
      "         0.1265, -0.0923,  0.0593, -0.0384, -0.0522, -0.0790,  0.1762, -0.0917,\n",
      "         0.0624,  0.0614, -0.0761, -0.0051, -0.0876,  0.1221, -0.1156, -0.0207,\n",
      "        -0.0894, -0.0218, -0.0139,  0.2351], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "FC1_SIZE is :432\n",
      "FC2_SIZE is 100\n",
      "加载后:  tensor([ 8.5771e-02,  8.2893e-02,  2.9989e-04,  2.5167e-01, -3.9782e-02,\n",
      "        -1.3033e-01,  3.7071e-02, -4.7115e-02, -1.1517e-01,  1.1474e-01,\n",
      "         2.6984e-04,  2.3895e-02,  4.0465e-02, -7.5408e-02,  1.6515e-01,\n",
      "         2.9334e-02,  8.9822e-02,  5.6914e-02,  2.4134e-03,  7.2515e-02,\n",
      "        -7.0146e-02,  1.7855e-01, -4.7037e-02, -9.7172e-02, -5.2332e-02,\n",
      "        -5.9581e-02,  1.3361e-01, -2.7890e-01,  1.2614e-01, -1.0190e-02,\n",
      "         3.3312e-02, -1.3389e-01,  9.6447e-02,  1.1891e-01, -1.9364e-01,\n",
      "        -9.5833e-02, -1.7680e-01,  3.1656e-02,  1.4360e-01,  1.5022e-01,\n",
      "        -9.0343e-02, -3.6031e-02, -6.7894e-02, -8.7544e-03, -1.2864e-01,\n",
      "         7.0672e-02,  6.6692e-02, -2.1154e-01, -4.8113e-02, -1.9171e-02,\n",
      "         6.8782e-02, -9.7572e-02,  9.4008e-02, -8.6491e-02, -1.8732e-01,\n",
      "        -1.1642e-01, -9.1366e-02, -8.2437e-02, -2.0030e-01,  7.2686e-02,\n",
      "        -8.6771e-02, -3.0729e-02,  3.4170e-02,  9.2935e-03,  4.3812e-02,\n",
      "         9.9356e-02, -6.1389e-02,  5.3799e-03,  7.1315e-02, -4.8571e-02,\n",
      "        -7.6135e-02,  9.7307e-02,  6.8910e-02, -1.2338e-01, -1.2439e-01,\n",
      "         2.5677e-01,  3.7560e-02, -3.0454e-02,  8.9420e-02, -2.9991e-01,\n",
      "         1.1783e-01,  1.0420e-01,  6.6444e-02,  8.4114e-02, -2.0698e-01,\n",
      "        -1.2826e-02,  2.0711e-02, -9.2982e-02,  1.3928e-01, -3.7020e-02,\n",
      "         9.1993e-02,  1.0946e-01,  7.5490e-03,  3.4127e-02,  3.9924e-02,\n",
      "        -1.4589e-01, -1.1178e-01,  8.1400e-02, -1.0273e-01, -1.3563e-01,\n",
      "         2.0994e-01, -5.0885e-02,  7.9368e-02,  1.7551e-01,  1.7240e-01,\n",
      "        -8.6579e-02, -3.3029e-02, -7.5773e-02,  7.3683e-02, -1.4790e-01,\n",
      "         7.5803e-02,  8.7282e-02, -6.5445e-02,  2.1549e-01, -5.9998e-02,\n",
      "         7.6188e-02,  1.1780e-01, -7.3360e-02,  1.5152e-01, -1.5206e-01,\n",
      "        -6.6050e-02,  1.9279e-02,  1.1913e-01,  9.7800e-02,  2.0570e-02,\n",
      "        -6.3100e-02,  4.4912e-02, -2.8492e-02,  5.9982e-04,  4.9593e-02,\n",
      "         7.8661e-02,  5.5441e-02,  1.0082e-01,  2.1470e-01,  1.4054e-01,\n",
      "        -1.9942e-01,  2.6428e-02, -2.2998e-02,  7.0160e-02, -1.1156e-01,\n",
      "         3.2697e-02,  8.1622e-02,  7.5199e-02,  4.0662e-02,  9.4874e-02,\n",
      "        -1.0143e-01, -2.3258e-02, -1.2084e-02, -1.0897e-01,  2.6394e-01,\n",
      "        -1.1309e-01,  3.6610e-02,  5.1395e-03, -4.7884e-02,  1.6900e-01,\n",
      "        -5.7169e-02,  1.4499e-02,  6.3972e-02, -3.1049e-02, -1.0035e-01,\n",
      "         7.1678e-02, -1.8001e-01,  8.7759e-02,  2.1420e-01,  6.3939e-02,\n",
      "         4.9873e-03, -1.9759e-01,  3.3989e-02,  4.1145e-02,  2.0638e-02,\n",
      "        -1.0124e-02,  9.4100e-02, -1.3991e-01,  2.6557e-03, -8.0599e-03,\n",
      "        -8.9561e-02, -9.3716e-02, -4.5878e-02, -1.3239e-01, -2.0797e-01,\n",
      "        -2.5367e-02,  2.0048e-02, -3.8200e-02, -3.5516e-02,  8.0279e-02,\n",
      "         5.1920e-02, -3.2877e-02, -5.2184e-02, -3.4117e-02,  4.3272e-02,\n",
      "        -1.5796e-01,  2.4609e-01,  7.0032e-02, -1.0496e-01, -4.7098e-02,\n",
      "         1.4853e-02, -1.6327e-02, -4.4201e-02,  7.4975e-02,  5.5702e-02,\n",
      "         1.9652e-02,  1.2854e-01, -7.0572e-02, -6.9395e-03,  3.9621e-02,\n",
      "         2.9728e-02,  5.7224e-02, -3.5591e-02, -4.6465e-03,  1.3282e-01,\n",
      "        -9.2425e-02,  4.8499e-02, -3.1205e-02,  1.3564e-02, -1.1527e-01,\n",
      "        -6.3016e-02], device='cuda:0', grad_fn=<SelectBackward>)\n",
      "FC1_SIZE is :128\n",
      "FC2_SIZE is 100\n",
      "加载后:  tensor([ 0.0677, -0.1045,  0.0225, -0.0609,  0.1043, -0.0121,  0.0777,  0.0901,\n",
      "         0.0263,  0.0455,  0.1778,  0.0525, -0.0056,  0.1020,  0.0877,  0.0143,\n",
      "         0.0507, -0.1415, -0.0159, -0.0684, -0.0340, -0.0453,  0.1253, -0.0373,\n",
      "         0.2039, -0.0091,  0.0402, -0.1799, -0.0581, -0.2722, -0.1770,  0.0207,\n",
      "         0.1899, -0.0190, -0.0575,  0.0323, -0.0574,  0.0844, -0.0974,  0.0717,\n",
      "         0.0137, -0.0663,  0.1941, -0.0986,  0.1165, -0.0295, -0.0611, -0.0197,\n",
      "         0.1645, -0.1761,  0.0293,  0.0514, -0.0290, -0.0223,  0.1830, -0.1839,\n",
      "         0.0835,  0.1838, -0.0249,  0.0311,  0.0420,  0.1421,  0.0390, -0.0869],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "FC1_SIZE is :480\n",
      "FC2_SIZE is 100\n",
      "加载后:  tensor([-8.7115e-02, -1.4350e-02, -5.2504e-02,  1.2084e-01,  2.1723e-02,\n",
      "        -7.9748e-02, -1.2125e-01,  1.9933e-01, -1.1522e-01, -1.2416e-01,\n",
      "         1.1166e-01, -1.2662e-01,  1.2570e-02, -5.3311e-02, -1.7340e-01,\n",
      "        -2.4279e-02,  5.0121e-02, -2.1487e-01,  1.0209e-01,  1.2790e-01,\n",
      "         1.9777e-01,  5.4392e-02,  8.4014e-02,  6.8459e-02,  4.8118e-02,\n",
      "         2.6106e-02,  1.5018e-01, -4.9810e-03, -1.1878e-02,  9.5490e-02,\n",
      "        -1.3091e-01, -8.2358e-02, -6.3142e-02, -1.3689e-02, -1.6256e-01,\n",
      "        -4.6627e-03,  4.8416e-02,  1.6410e-01,  8.0844e-02, -2.0607e-01,\n",
      "         1.6424e-01,  4.0757e-05,  5.0278e-02,  5.2381e-02,  2.4818e-02,\n",
      "        -1.1548e-01,  7.9933e-02, -3.6935e-02, -6.3799e-02, -5.2580e-02,\n",
      "        -1.3349e-01,  5.4320e-02, -5.1083e-02, -2.2140e-03,  2.4821e-02,\n",
      "         5.2229e-02,  6.7148e-02, -2.6593e-02,  1.7642e-01, -1.6401e-01,\n",
      "         1.0805e-01,  1.4398e-01,  2.4049e-02, -3.5329e-02, -2.3982e-02,\n",
      "         6.0658e-02, -8.9468e-02, -1.4924e-02,  4.7498e-03, -6.0933e-02,\n",
      "        -1.5500e-01,  1.9151e-02,  1.5971e-01,  8.0236e-02,  2.1901e-01,\n",
      "         3.6435e-04, -1.6481e-01, -1.2436e-01, -3.1220e-02, -2.2205e-01,\n",
      "         5.6389e-02, -7.4721e-02,  7.2427e-02, -8.3028e-02, -1.1341e-01,\n",
      "         6.1046e-02,  7.4253e-02,  2.0316e-01,  6.4356e-02, -6.8744e-02,\n",
      "        -7.8310e-02, -4.3946e-02, -8.0698e-02,  7.5458e-02,  1.6377e-01,\n",
      "         5.7597e-02,  6.1689e-02,  4.8686e-02,  1.0936e-01,  5.3469e-03,\n",
      "         3.6305e-03, -2.4015e-02,  3.2900e-02,  4.9307e-02, -1.7264e-01,\n",
      "         4.0633e-03,  1.7697e-01,  6.7826e-02,  1.3538e-02, -2.6849e-02,\n",
      "         1.7223e-02,  2.8448e-02, -1.4077e-01, -1.6998e-02,  1.5080e-01,\n",
      "         3.8619e-02,  7.7309e-02,  7.0275e-02, -1.2108e-01, -1.3872e-01,\n",
      "         6.6074e-02, -1.5523e-01,  1.3496e-01,  1.1056e-02, -4.7705e-02,\n",
      "         1.0401e-01,  1.7281e-02,  6.4059e-03, -6.4347e-02,  1.8156e-01,\n",
      "         5.0567e-02, -1.2942e-01,  5.0446e-02,  4.8492e-02, -1.5929e-02,\n",
      "        -1.4484e-03,  1.7060e-01, -3.2188e-02,  3.0022e-02, -3.7862e-02,\n",
      "        -1.9566e-01, -1.4834e-01,  1.0097e-02,  5.9606e-02,  4.1777e-02,\n",
      "         1.1466e-03, -4.0153e-02, -7.5647e-02,  4.4498e-02, -4.2329e-02,\n",
      "         1.2182e-01,  1.3428e-01, -1.3372e-01,  1.2333e-02,  4.1467e-02,\n",
      "        -1.9889e-01, -1.0386e-01, -1.5584e-01, -5.2356e-02,  4.9690e-03,\n",
      "        -1.4235e-02,  1.1609e-02,  6.8124e-02,  3.5160e-02,  6.5285e-02,\n",
      "         1.3604e-01, -1.4045e-01,  1.4421e-02,  1.2432e-01, -1.2241e-01,\n",
      "        -3.9606e-02, -8.9498e-02,  1.3836e-01, -1.0149e-01, -1.2511e-02,\n",
      "         8.7080e-02,  7.0015e-02,  1.7428e-01, -2.2814e-04,  2.0968e-02,\n",
      "         9.6118e-02,  2.0014e-02, -9.1145e-02, -3.8063e-03,  4.5411e-02,\n",
      "        -5.7374e-02,  6.9530e-02,  1.1477e-01,  4.9881e-02,  1.1724e-01,\n",
      "         2.5003e-02, -4.3276e-02, -1.4357e-01, -1.0478e-01,  1.9437e-01,\n",
      "         7.9140e-02,  1.0928e-01,  9.6797e-02,  1.1725e-01, -5.5540e-02,\n",
      "        -8.1953e-02, -7.7240e-02, -1.7114e-01, -1.0943e-02,  1.5672e-01,\n",
      "         1.3143e-01, -1.0429e-01, -1.3127e-01, -9.1296e-02,  4.8125e-02,\n",
      "         5.1937e-03, -1.1082e-01,  1.2478e-01,  6.8366e-02,  1.3700e-01,\n",
      "        -1.6575e-02,  1.7753e-01,  7.2437e-03,  2.2148e-02,  1.2854e-01,\n",
      "         2.6429e-02,  1.6692e-02,  6.4924e-03, -3.3306e-02,  1.2740e-01,\n",
      "         1.0506e-01, -9.3008e-02,  2.4994e-02,  4.3275e-02, -2.2487e-01,\n",
      "        -1.3931e-01, -9.6752e-02, -5.3065e-02,  8.2614e-02,  4.2778e-02,\n",
      "         1.7315e-03, -1.1748e-01, -1.2345e-01, -2.9601e-02,  5.7442e-02],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n",
      "FC1_SIZE is :94\n",
      "FC2_SIZE is 100\n",
      "加载后:  tensor([-0.0460, -0.0580, -0.1010, -0.0229, -0.0334,  0.4157, -0.2434, -0.2550,\n",
      "        -0.0132,  0.0326,  0.0304, -0.0705,  0.0560,  0.1156,  0.0735, -0.1101,\n",
      "         0.0282,  0.1398, -0.2304,  0.0915, -0.1332,  0.0353, -0.0566,  0.0286,\n",
      "        -0.1321, -0.1304,  0.0692, -0.1430, -0.1253, -0.0621, -0.1911, -0.0792,\n",
      "         0.2059, -0.1079, -0.0839, -0.2467, -0.0127, -0.0922, -0.0429,  0.2636,\n",
      "        -0.0346,  0.0534, -0.1002, -0.0818,  0.1540, -0.0043,  0.0736],\n",
      "       device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_set = list()\n",
    "dataset_set = list()\n",
    "dataloader_set = list()\n",
    "for i, file_name in enumerate(featureSet_list):\n",
    "    train_file_path = '../datasets/Handwritten/mfeat/splite/' + file_name + '/train_data.npy'\n",
    "    model_path = \"../saved_model/\" + file_name + \".pkl\"\n",
    "\n",
    "    dataset_set.append(handWritten_Dataset(data_path=train_file_path))\n",
    "#     train_loader = torch.utils.data.DataLoader(dataset=dataset_set[i], batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    model_set.append(MLP(classes=10, input_size=dataset_set[i].get_features_size()).to(device))\n",
    "    state_dict_load = torch.load(model_path)\n",
    "    model_set[i].load_state_dict(state_dict_load)\n",
    "    print(\"加载后: \", model_set[i].fc1.weight[0, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f11c0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_set[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf12be19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6687, 0.7048, 0.4109,  ..., 0.7064, 0.2379, 0.9506],\n",
       "        [0.7398, 0.6648, 0.9866,  ..., 0.0376, 0.3576, 0.1309],\n",
       "        [0.9410, 0.3109, 0.5236,  ..., 0.8389, 0.4405, 0.5823],\n",
       "        ...,\n",
       "        [0.7375, 0.5014, 0.7620,  ..., 0.5307, 0.4031, 0.8104],\n",
       "        [0.2523, 0.6842, 0.1313,  ..., 0.1358, 0.8581, 0.6817],\n",
       "        [0.1029, 0.5743, 0.6792,  ..., 0.4843, 0.8884, 0.3806]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand((1600,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8d34f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:FL] *",
   "language": "python",
   "name": "conda-env-FL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
